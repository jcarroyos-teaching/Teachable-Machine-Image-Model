# Predictions2dataviz
Esta actividad combina programación, inteligencia artificial y análisis de datos, promoviendo el pensamiento computacional y el desarrollo de habilidades creativas en tecnologías interactivas.

![tableau](https://github.com/user-attachments/assets/7dffc43b-58e1-49da-96f0-49a6e211542d)

**Guía Pedagógica: Reconocimiento de Sonidos y Visualización de Datos**

### **Introducción**
En esta actividad, los estudiantes crearán una aplicación interactiva que detecta sonidos y responde visualmente a ellos. Utilizando JavaScript y TensorFlow.js, aprenderán a capturar y procesar datos de audio, activar respuestas visuales y almacenar predicciones en el navegador. Además, explorarán la visualización de los datos recopilados en Tableau Public.

### **Desarrollo de la Actividad**
El proceso inicia con una introducción a los modelos de reconocimiento de sonido y cómo se pueden utilizar para detectar eventos específicos, como un chasquido de dedos o un aplauso. Se explicará la importancia de la manipulación del DOM para generar respuestas visuales y se abordará el almacenamiento local de datos en JavaScript.

Los estudiantes implementarán el reconocimiento de sonidos en el navegador. Cuando el sistema detecte un chasquido, hará que una bolita salte en la pantalla, mientras que un aplauso activará una animación de trueno. Para ello, configurarán un modelo de reconocimiento de audio y definirán las funciones necesarias para procesar las predicciones. Cada evento será registrado con una marca de tiempo en `localStorage`.

Posteriormente, se incluirá una función que permita exportar los datos recopilados en formato CSV. Los estudiantes podrán descargar este archivo y utilizarlo en Tableau Public para realizar una exploración visual. En esta etapa, se les guiará en la creación de gráficos que muestren la frecuencia de cada tipo de sonido detectado, su distribución temporal y posibles correlaciones entre eventos.

### **Reflexión y Aplicaciones**
Al finalizar, los estudiantes discutirán sobre el impacto del reconocimiento de audio en la interacción humano-computadora. Reflexionarán sobre posibles mejoras al sistema, como la incorporación de nuevos sonidos o la combinación con otras tecnologías de visualización en tiempo real. 



